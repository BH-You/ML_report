\documentclass{llncs}

\usepackage{amsmath,amssymb}
\usepackage{alg}
\usepackage{booktabs}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage{color}

\Urlmuskip=0mu plus 1mu

\renewcommand\dblfloatpagefraction{.99}
\renewcommand\dbltopfraction{.9}
\renewcommand\floatpagefraction{.99}
\renewcommand\topfraction{.9}

\newcommand{\name}{\texttt{G-NPM}\xspace}
\newcommand{\npm}{\texttt{NPM}\xspace}
\newcommand{\todo}[1]{\texttt{\color{red}TODO:#1}}
\begin{document}


\title{G-NPM:  Local Citation Recommendation System  with Global Features}

\author{Byeonghyeon You, Seongmin Lee, Junbeom Lee, Jinhan Kim}

\institute{Korea Advanced Institute of Science and Technology\\Republic of Korea}

\maketitle

\begin{abstract}
Recommendations for citations can be useful for writing research papers and also the AI-complete problem because of the challenges to bridge semantic differences between quoted contexts and cited papers.
It is not always easy for a knowledgeable researcher to provide an accurate citation context for a cited article or to search for a suitable article to cite a given context.
In order to solve this problem, we propose a new approach, \name, by combining the global features to the existing local citation recommendation system~\cite{Huang:2015:NPM:2886521.2886655} that learns the semantic representation between citation contexts and cited papers using the neural probabilistic model. We showed that our approach is about two times more effective than the \npm in average rank, average at 10, and MRR.

\end{abstract}

\section{Introduction}
\label{sec:introduction}
As academic communities have published about the millions of research papers, finding appropriate citations become burdensome for researchers. Citation recommendation systems~\cite{ren2014cluscite,Huang:2015:NPM:2886521.2886655,Bethard:2010:ICL:1871437.1871517} have cut down the overload of finding citations by automatically suggesting papers which might be related to the topic.


There are two main categories in citation recommendation, global and local citation recommendation.
The first category, global citation recommendation, recommends a list of candidate papers by examining some part of the entire paper. In addition to examine the text, global citation recommendation systems use the external features such as information of author, venue, citation count, and h-index. These external features can make recommendation model more accurate.
The second category, local citation recommendation, recommends a list of candidate papers by just looking a sentence which is called citation context. Local citation recommendation systems only take citation context as an input, suggest papers which are relevant to that context. Intuitively, it is more practical to use than global citation recommendation systems.


Although the current state-of-the-art local citation recommendation system~\cite{Huang:2015:NPM:2886521.2886655} outperformed other approaches, it showed relatively poor in recommending well-cited papers. Since global and local has own advantages, in this project, we propose the new citation recommendation system which is local citation recommendation system with global external features. We use citation count as a global external feature.


\section{Background}
This section describes the two citation recommendation models which are baseline of our new model.

\subsection{Neural Probabilistic Model}
\npm(Neural Probabilistic Model)~\cite{Huang:2015:NPM:2886521.2886655} is local citation recommendation model that learns the citing paper with given citation contexts. Training is separated into two parts, word representation learning and document representation learning. To learn words, they used negative sampling~\cite{mikolov2013distributed} that is used to learn the distribution of words. To learn documents with words, they used noise-contrastive estimation~\cite{gutmann2010noise} that is used to learn the distribution of words and documents.

\subsection{Literature Search Model}
Literature search model~\cite{Bethard:2010:ICL:1871437.1871517} takes only abstract as input and produce a list of candidate papers. The main idea of this model is examining not only text alone, but also the relevant features like citation patterns, co-authorship networks and subject area matching.
It uses iterative process for learning weights between global features.

\section{\name: A new citation recommendation system}
\todo{SM}


\section{Experiments}
\subsection{Research Questions}
\todo{SM}

\begin{enumerate}
\item Does \name use global information(citation count) to improve the efficiency of citation recommendation system?
\item Is the \name a model that can be applied competently on systems with small input data?
\end{enumerate}
\subsection{Setup}
For all experiments, we used the same data set used in \npm which is a snapshot of Citeseer paper and citation database was obtained at Oct, 2013. The data is composed of three tables with unprocessed SQL data(about 90GB): citation table, citation context table, and paper table. The citation table consists of cited paper id and citing paper id. The citation context table consists of the cited paper id and its context. One citation context consists of the sentence where a citation appears, as well as the sentences that appear before and after. The paper table consists of paper id. As a result, all the data set contains about 10,000,000 contexts and about 1,000,000 unique papers.
It took four days to only import the data set and we could not use as many resources as \npm used for their experiments. Therefore, we randomly extracted one from the original data. The training data is consisted of 10,520 contexts and 5,613 cited papers. As test data, 999 contexts and corresponding 359 papers were randomly selected and tested.


Table 1

For text normalization, rare words that appear less than five times are filtered out and we did not distinguish between uppercase/lowercase words. In all experiments, we use the citation contexts and cited papers extracted from the test set as ground truth. Unlike the target paper, the number of recommendations is not limited to 10 for each query because we only trained small amount of data which is causing less effective recommendation performance.

\subsection{Evaluation Metric}
We used three well-known metrics which are average rank, average rank at 10 and Mean Reciprocal Rank(MRR) on the information retrieval system to evaluate the ranking obtained from \name. The average rank is the average value of recommended ranking. The rank means the order of the papers that are likely to be recommended. Average ranking at 10 is the average value of recommended ranking where the appropriate cited paper was assigned within top 10. The MRR is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer.


\section{Results}
\todo{BH}

\section{Discussion}
\todo{BH}

\section{Conclusion}
\label{sec:Conclusion}
\todo{BH}


\bibliographystyle{splncs03}
\bibliography{ref}

\end{document}
