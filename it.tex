\documentclass{llncs}

\usepackage{amsmath,amssymb}
\usepackage{alg}
\usepackage{booktabs}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage{color}

\Urlmuskip=0mu plus 1mu

\renewcommand\dblfloatpagefraction{.99}
\renewcommand\dbltopfraction{.9}
\renewcommand\floatpagefraction{.99}
\renewcommand\topfraction{.9}

\newcommand{\name}{\texttt{G-NPM}\xspace}
\newcommand{\npm}{\texttt{NPM}\xspace}
\newcommand{\todo}[1]{\texttt{\color{red}TODO:#1}} 
\begin{document}


\title{G-NPM : Local Citation Recommendation System  With Global-Features}

\author{Byeonghyeon You\inst{1}, Seongmin Lee\inst{1}, Junbeom Lee\inst{1}, Jinhan Kim\inst{1}}

\institute{Korea Advanced Institute of Science and Technology, Republic of Korea}

\maketitle

\begin{abstract}
\todo{JB}

\end{abstract}

\section{Introduction}
\label{sec:introduction}
\todo{JH}

\section{Background}
\todo{JH}
\subsection{Neural Probabilistic Model}
Neural Probabilistic Model, \npm ~\cite{Huang:2015:NPM:2886521.2886655}
\subsection{Literature Search Model}
Literature Search Model~\cite{Bethard:2010:ICL:1871437.1871517}

\section{\name: A new citation recommendation system}
\todo{SM}
The state of art npm 모델의 main contribution point 중 하나의 less cited 된 paper에 대한 recomentation 이다. paper 가 적게 cited 되었다는 것은, 다른 말로 하면 그 paper 에 대한 training data가 부족하다는 말과 같다. training data의 양은 learning 의 결과에 큰 영향을 미칠 수 있고, 따라서 적게 cited 된 paper를 well recommendation 하는 것은 citation recommendation system에서 어려운 task 중 하나이다. npm 이 다른 model 들과 비교하였을 때 less cited paper 에 대해서 잘 recommend 했다는 것은 그들의 큰 강점이다.
그러나 이와 같은 npm의 장점에도 불구하고 npm은 플어야 할 숙제가 몇가지가 있다. 먼저 less cited paper에 대한 큰 improvement에 비하여, well cited paper 에 대한 recommendation 의 성적은 다른 모델에 비해서 크게 달라진 점은 없다. npm은 각 paper에 대한 external 한 information 은 사용하지 않고 오로지 text 기반으로 learning을 하였다. 따라서 well cited paper 들이 더욱 많은 training information을 가지고 있음에도 불구하고 이에 대한 advantage를 충분히 활용하고 있지 못하다. 또한 npm은 굉장히 큰 데이터를 필요로 한다. 비록 주어진 데이터에 대해서 적은 volume을 차지하는 less cited paper에 대해서 결과를 잘 내어놓을 순 있었지만 이 때 사용되었던 데어터의 양은 ... 로 매우 컸다. We found out that, the training data size for this paper was over 90Gb. And the developer said the training time took a week with 24-core cpu to get to 200 iterations.
[따라서 global을 쓸꺼다, linear sum 으로 global 한 feature를 넣을꺼고, 그에 따른 효과는 이러이러할 것이라고 생각한다.] Then, we found several papers, those use, not textual informations but global informations to recommend the paper, such as number of citations, venue, h-index, etc.
These global features are worthy features.
It is appropriate features to enhance the performance of well-cited papers.
Also, adding the new features to the model can help to reduce the importance of the amount of training data.

\section{Experiments}
\subsection{Research Questions}
\todo{SM}

[위에서 말한 효과를 검증하기 위하여 다음과 같은 research question을 설정한다.]
\begin{enumerate}
\item Does G-NPM use global information(citation count) to improve the efficiency of citation recommendation system?
\item Is the G-NPM a model that can be applied competently on systems with small input data?
\end{enumerate}
\subsection{Setup}
\todo{JB}

\subsection{Evaluation Metric}
\todo{JB}

\section{Results}
\todo{BH}

\section{Discussion}
\todo{BH}

\section{Conclusion}
\label{sec:Conclusion}
\todo{BH}


\bibliographystyle{splncs03}
\bibliography{ref}


\end{document}
